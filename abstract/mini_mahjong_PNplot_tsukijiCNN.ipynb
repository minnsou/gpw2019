{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tkLa-ZvjEvPc"
   },
   "source": [
    "やりたいこと\n",
    "\n",
    "・引ける牌の確率が変わったとき（手牌にある牌はその分引きづらくなるとか）のvalueを求める\n",
    "\n",
    "・18種や27種（マンズだけでなく、ピンズやソーズも増やす）時のvalueを求める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXkJ_f1MEvPc"
   },
   "source": [
    "面倒なので、まずは最大でも１色とする(n<=9)、手牌は14枚以下(m=3, 5, 8, 11, 14のみ)、同一牌は4枚(l = 4)でこれは固定。この条件でvalueを求める。\n",
    "\n",
    "\n",
    "\n",
    " **変数の意味**\n",
    "\n",
    "- state : あがりに必要な枚数の手牌の状態\n",
    "\n",
    "- hand : stateから一枚切った状態"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JiMFUnpH-fQ5"
   },
   "source": [
    "### 必要な関数の再定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwuINT6T-fQ6"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def is_valid(seq, l=4): # 生成された組み合わせが手牌として妥当かどうかを判断する関数　tuple(seq)の一つ一つが一つの状態(手牌)に対応している\n",
    "    counts = defaultdict(lambda: 0)\n",
    "    for i in range(0, len(seq)):\n",
    "        if i + 1 < len(seq) and seq[i] > seq[i + 1]: # 前半の条件はiが一番最後以外は常に成立、後半の条件は昇順に整列するための条件\n",
    "            return False\n",
    "        counts[seq[i]] += 1\n",
    "        if (counts[seq[i]] > l): return False # 牌の上限枚数を超えたらFalse\n",
    "    return True\n",
    "\n",
    "import itertools\n",
    "def number_state_slow(n,m,l): # 全ての手牌の組み合わせの数を出力する関数\n",
    "    count = 0\n",
    "    for seq in itertools.product(range(n), repeat = m): # 直積を作る関数, n=9 m=5 なら 9 ** 5 回繰り返す　\n",
    "        if is_valid(seq,l):\n",
    "            count += 1\n",
    "            #print(list(seq))\n",
    "    return count\n",
    "    \n",
    "def generate_all_l(n, m, l=4): # 全ての手牌の組み合わせをタプルで出力する関数\n",
    "    gen_list = []\n",
    "    for seq in itertools.product(range(n), repeat = m):\n",
    "        if is_valid(seq, l):\n",
    "            gen_list.append(seq)\n",
    "    return gen_list\n",
    "\n",
    "def states_to_hist(state_list, n): # 手牌(state)を、牌種ごとの枚数のリスト(長さn)に変換する関数\n",
    "    hist_list = []\n",
    "    for state in state_list:\n",
    "        #print(state)\n",
    "        ret = [0] * n # ret = [0,0,...,0]\n",
    "        for c in state:\n",
    "            ret[c] += 1\n",
    "        hist_list.append(ret)\n",
    "    return hist_list\n",
    "\n",
    "def hand_to_prob_and_state(hand, state_nml, n, m, l=4): # ある手牌(hand)における、1枚ツモる時の遷移確率(prob)と手牌(state)のindexのタプルを出す関数\n",
    "    #print(state_nml)\n",
    "    ret = [l] * n  #  残り枚数を表すリスト\n",
    "    for h in hand:\n",
    "        ret[h] -= 1\n",
    "    yama_sum = n * l - (m - 1)\n",
    "    state_list = []\n",
    "    for i in range(n):\n",
    "        if ret[i] == 0: \n",
    "            continue\n",
    "        prob = ret[i] / yama_sum # 遷移確率\n",
    "        state = tuple(sorted(list(hand) + [i])) # 遷移後の手牌\n",
    "        #print(state)\n",
    "        state_index = state_nml.index(state) # 遷移後の手牌のindex\n",
    "        #print(state_index)\n",
    "        state_list.append((prob, state_index))\n",
    "    return state_list\n",
    "\n",
    "def state_to_hand(state): # ある手牌stateに遷移できるhandを出力する関数\n",
    "    return list(set(tuple(state[:i] + state[i+1:]) for i in range(len(state)))) # i番目の要素を取り除く\n",
    "\n",
    "def is_win_sub(hist, two, three):\n",
    "    if any(x < 0 for x in hist):\n",
    "        return False # この行を消したかったら、順子判定のところで手牌の枚数が負になるものを弾いておく\n",
    "    if two == 0 and three == 0:\n",
    "        return True\n",
    "    i = next(i for i, x in enumerate(hist) if x > 0) # histの中でx>０を満たす最小のindexを持ってくる\n",
    "    if two > 0 and hist[i] >= 2 and is_win_sub([x - 2 if i == j else x for j, x in enumerate(hist)], two - 1, three): # 雀頭\n",
    "        return True\n",
    "    if three > 0 and hist[i] >= 3 and is_win_sub([x - 3 if i == j else x for j, x in enumerate(hist)], two, three - 1): # 刻子\n",
    "        return True\n",
    "    if three > 0 and i + 2 < len(hist) and is_win_sub([x -1 if i <= j <= i + 2 else x for j, x in enumerate(hist)], two, three - 1): # 順子\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_win_main(hist):\n",
    "    n_two = 1 if sum(hist) % 3 == 2 else 0\n",
    "    n_three = sum(hist) // 3\n",
    "    return is_win_sub(hist, n_two, n_three)\n",
    "\n",
    "def value_iteration(n, m, l, gamma):\n",
    "    state_nml = generate_all_l(n, m, l)\n",
    "    hand_nml = generate_all_l(n, m-1, l)\n",
    "    hist_nml = states_to_hist(state_nml, n)\n",
    "    is_win_nml = [is_win_main(hist) for hist in hist_nml]\n",
    "    h2ps_nml = [hand_to_prob_and_state(hand, state_nml, n, m, l) for hand in hand_nml]\n",
    "    s2h_nml = [[hand_nml.index(hand) for hand in state_to_hand(state)] for state in state_nml]\n",
    "    value_hand = [0] * len(hand_nml)\n",
    "    n_hand = len(hand_nml)\n",
    "    value_state = [1 if is_win_nml[i] else 0 for i in range(len(state_nml))] # あがっていればvalueは1、いなければ0\n",
    "    n_state = len(state_nml)\n",
    "    theta = 1e-6\n",
    "    while True:\n",
    "        print('iteration')\n",
    "        delta = 0\n",
    "        for i in range(n_hand):\n",
    "            old_v = value_hand[i]\n",
    "            value_hand[i] = sum(p * value_state[n] for (p, n) in h2ps_nml[i])\n",
    "            delta = max(delta, abs(old_v - value_hand[i]))\n",
    "        if delta < theta: break\n",
    "        for i in range(n_state):\n",
    "            if is_win_nml[i]: continue\n",
    "            value_state[i] = max(gamma * value_hand[n] for n in s2h_nml[i])\n",
    "    return value_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-o87MJySd7Ah"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "random_seed = 34\n",
    "np.random.seed(random_seed)\n",
    "#tf.set_random_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rMZ_OK-fFHM"
   },
   "outputs": [],
   "source": [
    "def one_hot_vector1(hands, n): # 手牌の中の牌一つ一つをone-hotにした(手牌１つがn * m-1の行列に対応)\n",
    "    results = np.zeros((len(hands), n, len(hands[0])))\n",
    "    for i in range(len(hands)):\n",
    "        for j, hand_i in enumerate(hands[i]):\n",
    "            results[i][hand_i][j] = 1\n",
    "    return results\n",
    "\n",
    "def one_hot_vector2(hists, n, l=4): # histをそのままone-hotにした(手牌１つがn * l + 1の行列に対応)\n",
    "    results = np.zeros((len(hists), n, l + 1))\n",
    "    for i in range(len(hists)):\n",
    "        for j, hist_i in enumerate(hists[i]):\n",
    "            results[i][j][hist_i] = 1\n",
    "    return results\n",
    "\n",
    "def one_hot_vector3(hists, n, l=4): # 上に近いけど、持ってる枚数より小さい数も1で埋めた(手牌１つがn * lの行列に対応)\n",
    "    results = np.zeros((len(hists), n, l))\n",
    "    for i in range(len(hists)):\n",
    "        for j, hist_i in enumerate(hists[i]):\n",
    "            if hist_i == 0:\n",
    "                continue\n",
    "            else:\n",
    "                results[i][j][:hist_i] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xhvsLPaPW8YT"
   },
   "source": [
    "### 捨て牌ベクトルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "colab_type": "code",
    "id": "SloFByrwWqgy",
    "outputId": "0a51d881-6d5c-406e-ad0d-ca6b35e49e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n"
     ]
    }
   ],
   "source": [
    "n = 9\n",
    "m = 5\n",
    "l = 4\n",
    "\n",
    "value_hand_nml = value_iteration(n, m, l, 0.9)\n",
    "state_nml = generate_all_l(n, m, l)\n",
    "hand_nml = generate_all_l(n, m - 1, l)\n",
    "#print(len(hand_nml))\n",
    "#print(hand_nml)\n",
    "#print(value_hand_nml)\n",
    "\n",
    "def state_to_hist(state, n): # 手牌(state)を、牌種ごとの枚数のリスト(長さn)に変換する関数\n",
    "    hist = [0] * n # hist = [0,0,...,0]\n",
    "    for c in state:\n",
    "        hist[c] += 1\n",
    "    return hist\n",
    "\n",
    "# stateとその時にvalueが最大となる捨て牌のタプルを入れたリスト max_value_discard_list = [((0, 0, 0, 0, 1), {0}), ((0, 0, 0, 0, 2), {0}), ... ,((7, 8, 8, 8, 8), {8})]\n",
    "# state_nmlのうち、あがり形を抜いたもの discard_state_nml = [(0, 0, 0, 0, 1), (0, 0, 0, 0, 2), ..., (7, 8, 8, 8, 8)]\n",
    "def states_to_max_value_list(state_nml, hand_nml, value_hand_nml, n, m, l=4):\n",
    "    max_value_list = []\n",
    "    discard_state_nml = []\n",
    "    hist_nml = states_to_hist(state_nml, n)\n",
    "    for i, hist in enumerate(hist_nml):        \n",
    "        if is_win_main(hist):\n",
    "            continue # あがっているstateの時は何も入れない\n",
    "        else:\n",
    "            max_value = 0\n",
    "            max_p = []\n",
    "            for j in range(m):\n",
    "                state = state_nml[i]\n",
    "                hand = state[:j] + state[j+1:]\n",
    "                ind = hand_nml.index(tuple(hand))\n",
    "                hand_val = value_hand_nml[ind]\n",
    "                if max_value < hand_val:\n",
    "                    max_p = {state[j]}\n",
    "                    max_value = hand_val\n",
    "                elif round(max_value, 5) == round(hand_val, 5): # 小数点以下5桁まで同じなら同じとみなす\n",
    "                    max_p.add(state[j])\n",
    "            discard_state_nml.append(state_nml[i])\n",
    "            max_value_list.append(tuple((state_nml[i], max_p)))\n",
    "    return max_value_list, discard_state_nml # 正直discard_hist_nmlを出す方が早い\n",
    "\n",
    "# 各stateにおいて、出力してほしい捨て牌の確率分布を出力する\n",
    "def discard_ans_prob_vector(max_value_discard_list, n, m, l):\n",
    "    discard_vector = []\n",
    "    for i, discard in max_value_discard_list:\n",
    "        v = [0] * n\n",
    "        num = len(discard)\n",
    "        for p in discard:\n",
    "            v[p] = 1 / num # 答えの数で割った値を教師とする  こうしないと学習がうまくいかない?\n",
    "            #v[p] = 1\n",
    "        discard_vector.append(v)\n",
    "    return discard_vector\n",
    "\n",
    "n = 34\n",
    "max_value_discard_list, discard_state_nml = states_to_max_value_list(state_nml, hand_nml, value_hand_nml, n, m, l)\n",
    "#for i in max_value_discard_list: print(i) \n",
    "discard_hist_nml = states_to_hist(discard_state_nml, n)\n",
    "discard_ans_vector_nml = np.array(discard_ans_prob_vector(max_value_discard_list, n, m, l))\n",
    "#print(discard_ans_vector_nml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zIhZjK0rCc2v"
   },
   "outputs": [],
   "source": [
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % (self.epochs // 5) == 0: print(logs.get('loss'))\n",
    "        if epoch % 10 == 0: print('.', end='')\n",
    "\n",
    "# discard_state_nmlをone_hot化する関数\n",
    "def one_hot(discard_state_nml, num):\n",
    "    if num == 1:\n",
    "        return one_hot_vector1(discard_state_nml, n)\n",
    "    elif num == 2:\n",
    "        discard_hist_nml = states_to_hist(discard_state_nml, n)\n",
    "        return one_hot_vector2(discard_hist_nml, n, l)\n",
    "    else:\n",
    "        discard_hist_nml = states_to_hist(discard_state_nml, n)\n",
    "        return one_hot_vector3(discard_hist_nml, n, l)\n",
    "\n",
    "# predictionsから求めた捨て牌のリストを返す関数\n",
    "def make_pred_arg_list_split(predictions, discard_state_test):\n",
    "    pred_arg_list = []\n",
    "    for i  in range(len(predictions)):\n",
    "        tile = np.argmax(predictions[i])\n",
    "        if tile not in discard_state_test[i]:\n",
    "            max_val = 0\n",
    "            max_tile = 0\n",
    "            for t in discard_state_test[i]:\n",
    "                if predictions[i][t] > max_val:\n",
    "                    max_val = predictions[i][t]\n",
    "                    max_tile = t\n",
    "            tile = max_tile\n",
    "        pred_arg_list.append(tile)\n",
    "    return pred_arg_list\n",
    "\n",
    "# 正解率を返す関数\n",
    "def acc_score_split(pred_arg_list, discard_state_test): \n",
    "    tr_count = 0\n",
    "    fal_count = 0\n",
    "    for i, pred_arg in enumerate(pred_arg_list):\n",
    "        #print(i, j)\n",
    "        for state, discard_set in max_value_discard_list:\n",
    "            if discard_state_test[i] == state:\n",
    "                if pred_arg in discard_set:\n",
    "                    tr_count += 1\n",
    "                else:\n",
    "                    fal_count += 1\n",
    "    print('true count {}  false count {}'.format(tr_count, fal_count))\n",
    "    print('accuracy rate', tr_count / (tr_count + fal_count))\n",
    "    return tr_count / (tr_count + fal_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ka04ABPAfFHW"
   },
   "source": [
    "### Policy networkの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPDsXl0CtI3p"
   },
   "outputs": [],
   "source": [
    "# allFlter\n",
    "def train_policy_network(num, kernel_size_list, n_trials, EPOCHS):\n",
    "    start_time = time.time()\n",
    "    result_mean_dict  = {}\n",
    "    result_std_dict = {}\n",
    "    pred_acc_dict = {}\n",
    "    time_dict = {}\n",
    "    plt.figure()\n",
    "    \n",
    "    for k_num in kernel_size_list:\n",
    "        def build_model():\n",
    "            model = keras.Sequential([\n",
    "                layers.InputLayer(input_shape=(n, l, 1)),\n",
    "                layers.Conv2D(filters=32, kernel_size=(k_num, l)),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dropout(0.5),\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(400, activation='relu'),\n",
    "                layers.Dense(34, activation='softmax'),\n",
    "            ])\n",
    "            optimizer = keras.optimizers.Adam()\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "            return model\n",
    "\n",
    "        sum_acc_result = pd.Series([0] * EPOCHS)\n",
    "        final_acc_results = []\n",
    "        pred_acc_results = []\n",
    "        for i in range(n_trials):\n",
    "            model = build_model()\n",
    "            if i == 0:\n",
    "                model.summary()\n",
    "            discard_state_train, discard_state_test, discard_ans_vector_train, discard_ans_vector_test = train_test_split(discard_state_nml, discard_ans_vector_nml, test_size=0.25)\n",
    "            #print(discard_state_train[:5])\n",
    "            #print(discard_ans_vector_train[:5])\n",
    "            one_hot_discard_state_train = one_hot(discard_state_train, num).reshape(len(discard_state_train), n, l, 1)\n",
    "            one_hot_discard_state_test = one_hot(discard_state_test, num).reshape(len(discard_state_test), n, l, 1)\n",
    "            history = model.fit(one_hot_discard_state_train, discard_ans_vector_train, epochs=EPOCHS, validation_split = 0, verbose=0, callbacks=[PrintDot(EPOCHS)])\n",
    "            hist = pd.DataFrame(history.history)\n",
    "            hist['epoch'] = history.epoch\n",
    "            print('\\n',hist.tail())\n",
    "            sum_acc_result += hist['categorical_accuracy']\n",
    "            final_acc_results.append(hist['categorical_accuracy'][EPOCHS-1])\n",
    "            predictions = model.predict(one_hot_discard_state_test)\n",
    "            pred_arg_list = make_pred_arg_list_split(predictions, discard_state_test)\n",
    "            #print(predictions[:5], discard_state_test[:5], pred_arg_list[:5])\n",
    "            pred_acc_results.append(acc_score_split(pred_arg_list, discard_state_test))\n",
    "            print()\n",
    "\n",
    "        result_mean_dict[k_num] = round(np.mean(final_acc_results), 5)\n",
    "        result_std_dict[k_num] = round(np.std(final_acc_results), 6)\n",
    "        pred_acc_dict[k_num] = round(np.mean(pred_acc_results), 4)\n",
    "        time_dict[k_num] = round(time.time() - start_time, 1)\n",
    "        plt.plot(hist['epoch'], sum_acc_result / n_trials, label=str(k_num))\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('categorical accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    print('result acc mean\\n', result_mean_dict)\n",
    "    print('result acc std\\n', result_std_dict)\n",
    "    print('pred accuracy rate(mean)\\n', pred_acc_dict)\n",
    "    print('time (sec)\\n', time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NU9UHB1YndoX",
    "outputId": "00388f37-8c4f-4952-aab7-dedb285b2078"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0718 02:03:45.387578 4465178048 deprecation.py:506] From /Users/shimizutaishi/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 1, 32)         416       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 1, 32)         128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 400)               410000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 34)                13634     \n",
      "=================================================================\n",
      "Total params: 424,178\n",
      "Trainable params: 424,114\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "1.820598304897651\n",
      "............................................................0.03598822794920931\n",
      "............................................................0.02696549110929108\n",
      "............................................................0.02260841983588507\n",
      "............................................................0.017186463410707866\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.016992              0.987165   2995\n",
      "2996  0.017431              0.991832   2996\n",
      "2997  0.017436              0.992999   2997\n",
      "2998  0.017842              0.983664   2998\n",
      "2999  0.017526              0.984831   2999\n",
      "true count 245  false count 41\n",
      "accuracy rate 0.8566433566433567\n",
      "\n",
      "1.6969031788226188\n",
      "............................................................0.03173008065370793\n",
      "............................................................0.02256744774493151\n",
      "............................................................0.02416858710842047\n",
      "............................................................0.03084203355899704\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.020736              0.984831   2995\n",
      "2996  0.023132              0.987165   2996\n",
      "2997  0.019764              0.987165   2997\n",
      "2998  0.021539              0.987165   2998\n",
      "2999  0.020638              0.985998   2999\n",
      "true count 241  false count 45\n",
      "accuracy rate 0.8426573426573427\n",
      "\n",
      "1.98150501312425\n",
      "............................................................0.02812670044901986\n",
      "............................................................0.03271409895825564\n",
      "............................................................0.023097436292960374\n",
      "............................................................0.02403312106532956\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.033169              0.985998   2995\n",
      "2996  0.023837              0.981330   2996\n",
      "2997  0.021998              0.987165   2997\n",
      "2998  0.022222              0.981330   2998\n",
      "2999  0.027977              0.985998   2999\n",
      "true count 243  false count 43\n",
      "accuracy rate 0.8496503496503497\n",
      "\n",
      "1.7529098884644836\n",
      "............................................................0.040574650189979494\n",
      "............................................................0.023997295536947915\n",
      "............................................................0.023418232203323217\n",
      "............................................................0.024167904626024406\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.021539              0.982497   2995\n",
      "2996  0.025708              0.984831   2996\n",
      "2997  0.031799              0.983664   2997\n",
      "2998  0.021996              0.987165   2998\n",
      "2999  0.020804              0.991832   2999\n",
      "true count 241  false count 45\n",
      "accuracy rate 0.8426573426573427\n",
      "\n",
      "1.9040268943357077\n",
      "............................................................0.03593528496923062\n",
      "............................................................0.029918618254327404\n",
      "............................................................0.02434675459784602\n",
      "............................................................0.02337717988676106\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.023629              0.985998   2995\n",
      "2996  0.023286              0.987165   2996\n",
      "2997  0.022859              0.985998   2997\n",
      "2998  0.023358              0.980163   2998\n",
      "2999  0.023078              0.987165   2999\n",
      "true count 245  false count 41\n",
      "accuracy rate 0.8566433566433567\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 1, 32)         1184      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 26, 1, 32)         128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 26, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 832)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 400)               333200    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 34)                13634     \n",
      "=================================================================\n",
      "Total params: 348,146\n",
      "Trainable params: 348,082\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "1.9798261167844506\n",
      "............................................................0.02398099177902784\n",
      "............................................................0.023781422183597883\n",
      "............................................................0.019984824605076383\n",
      "............................................................0.01918791344985931\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.016590              0.983664   2995\n",
      "2996  0.017087              0.989498   2996\n",
      "2997  0.017338              0.985998   2997\n",
      "2998  0.017314              0.989498   2998\n",
      "2999  0.018160              0.987165   2999\n",
      "true count 244  false count 42\n",
      "accuracy rate 0.8531468531468531\n",
      "\n",
      "1.8992926097945544\n",
      "............................................................0.030988950757233725\n",
      "............................................................0.03720789208199694\n",
      "............................................................0.020601444856628837\n",
      "............................................................0.026402702845317608\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.018385              0.983664   2995\n",
      "2996  0.018310              0.981330   2996\n",
      "2997  0.020595              0.992999   2997\n",
      "2998  0.021451              0.984831   2998\n",
      "2999  0.018829              0.984831   2999\n",
      "true count 241  false count 45\n",
      "accuracy rate 0.8426573426573427\n",
      "\n",
      "2.007634593419461\n",
      "............................................................0.039473255634386105\n",
      "............................................................0.022803200308022676\n",
      "............................................................0.027741960354234648\n",
      "............................................................0.019276557781658453\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.020338              0.987165   2995\n",
      "2996  0.018251              0.992999   2996\n",
      "2997  0.019675              0.988331   2997\n",
      "2998  0.021142              0.980163   2998\n",
      "2999  0.019223              0.988331   2999\n",
      "true count 246  false count 40\n",
      "accuracy rate 0.8601398601398601\n",
      "\n",
      "1.9006773848238736\n",
      "............................................................0.042512718039861466\n",
      "............................................................0.02819587748297937\n",
      "............................................................0.025280497207264996\n",
      "............................................................0.025221555958210753\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.022615              0.983664   2995\n",
      "2996  0.022216              0.985998   2996\n",
      "2997  0.023955              0.983664   2997\n",
      "2998  0.022090              0.987165   2998\n",
      "2999  0.022773              0.983664   2999\n",
      "true count 242  false count 44\n",
      "accuracy rate 0.8461538461538461\n",
      "\n",
      "1.9958624661733835\n",
      "............................................................0.037978092506810446\n",
      "............................................................0.02684064312971685\n",
      "............................................................0.03180376232966842\n",
      "............................................................0.028742336494334112\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.024618              0.982497   2995\n",
      "2996  0.025101              0.981330   2996\n",
      "2997  0.025893              0.980163   2997\n",
      "2998  0.027767              0.983664   2998\n",
      "2999  0.024622              0.980163   2999\n",
      "true count 234  false count 52\n",
      "accuracy rate 0.8181818181818182\n",
      "\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 1, 1, 32)          4384      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1, 1, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 400)               13200     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 34)                13634     \n",
      "=================================================================\n",
      "Total params: 31,346\n",
      "Trainable params: 31,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "2.663861886762265\n",
      "............................................................0.33683762291626723\n",
      "............................................................0.30862664675629126\n",
      "............................................................0.29542296971851917\n",
      "............................................................0.25532355949786883\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.254903              0.901984   2995\n",
      "2996  0.248738              0.904317   2996\n",
      "2997  0.295468              0.892649   2997\n",
      "2998  0.209750              0.911319   2998\n",
      "2999  0.229942              0.918320   2999\n",
      "true count 252  false count 34\n",
      "accuracy rate 0.8811188811188811\n",
      "\n",
      "2.5110319569063577\n",
      "............................................................0.3702096457798534\n",
      "............................................................0.2836863219807557\n",
      "............................................................0.22550919864113717\n",
      "............................................................0.23925691450942774\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.188554              0.939323   2995\n",
      "2996  0.200099              0.919487   2996\n",
      "2997  0.219587              0.914819   2997\n",
      "2998  0.222182              0.914819   2998\n",
      "2999  0.231783              0.914819   2999\n",
      "true count 246  false count 40\n",
      "accuracy rate 0.8601398601398601\n",
      "\n",
      "2.602140556555785\n",
      "............................................................0.3246266819284566\n",
      "............................................................0.2964524375307379\n",
      "............................................................0.25703987445304105\n",
      "............................................................0.25540135978191847\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.222284              0.917153   2995\n",
      "2996  0.220831              0.919487   2996\n",
      "2997  0.227699              0.908985   2997\n",
      "2998  0.217575              0.921820   2998\n",
      "2999  0.253943              0.910152   2999\n",
      "true count 256  false count 30\n",
      "accuracy rate 0.8951048951048951\n",
      "\n",
      "2.6528872547795084\n",
      "............................................................0.34637401608561136\n",
      "............................................................0.30368431531492723\n",
      "............................................................0.28310794253749916\n",
      "............................................................0.25267506612501733\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.203694              0.924154   2995\n",
      "2996  0.238406              0.915986   2996\n",
      "2997  0.233743              0.907818   2997\n",
      "2998  0.231974              0.920653   2998\n",
      "2999  0.215392              0.926488   2999\n",
      "true count 253  false count 33\n",
      "accuracy rate 0.8846153846153846\n",
      "\n",
      "2.463224511441439\n",
      "............................................................0.3075412357076046\n",
      "............................................................0.2828345869601538\n",
      "............................................................0.2595382666121842\n",
      "............................................................0.28210923159136375\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.208485              0.921820   2995\n",
      "2996  0.234224              0.912485   2996\n",
      "2997  0.214082              0.911319   2997\n",
      "2998  0.258527              0.898483   2998\n",
      "2999  0.199697              0.924154   2999\n",
      "true count 245  false count 41\n",
      "accuracy rate 0.8566433566433567\n",
      "\n",
      "result acc mean\n",
      " {3: 0.98716, 9: 0.98483, 34: 0.91879}\n",
      "result acc std\n",
      " {3: 0.002448, 9: 0.002858, 34: 0.005977}\n",
      "pred accuracy rate(mean)\n",
      " {3: 0.8497, 9: 0.8441, 34: 0.8755}\n",
      "time (sec)\n",
      " {3: 1347.8, 9: 2649.7, 34: 3227.7}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 3\n",
    "n_trials = 5\n",
    "EPOCHS = 3000\n",
    "kernel_size_list = [3, 9, 34]\n",
    "train_policy_network(num, kernel_size_list, n_trials, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJCHZgoSndob"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AH18TWDwndoc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5a10KsIzn6dI"
   },
   "source": [
    "n = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0SmDovxndoe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n",
      "iteration\n"
     ]
    }
   ],
   "source": [
    "n = 9\n",
    "m = 8\n",
    "l = 4\n",
    "\n",
    "value_hand_nml = value_iteration(n, m, l, 0.9)\n",
    "state_nml = generate_all_l(n, m, l)\n",
    "hand_nml = generate_all_l(n, m - 1, l)\n",
    "#print(len(hand_nml))\n",
    "#print(hand_nml)\n",
    "#print(value_hand_nml)\n",
    "\n",
    "n = 34\n",
    "max_value_discard_list, discard_state_nml = states_to_max_value_list(state_nml, hand_nml, value_hand_nml, n, m, l)\n",
    "#for i in max_value_discard_list: print(i) \n",
    "discard_hist_nml = states_to_hist(discard_state_nml, n)\n",
    "discard_ans_vector_nml = np.array(discard_ans_prob_vector(max_value_discard_list, n, m, l))\n",
    "#print(discard_ans_vector_nml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlT4OmDYoETb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 32, 1, 32)         416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 1, 32)         128       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 400)               410000    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 34)                13634     \n",
      "=================================================================\n",
      "Total params: 424,178\n",
      "Trainable params: 424,114\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "1.3860286370487822\n",
      "............................................................0.10234847878280584\n",
      "............................................................0.08419041882673482\n",
      "............................................................0.07398387464976669\n",
      "............................................................0.06856535062675131\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.066631              0.977667   2995\n",
      "2996  0.065268              0.976255   2996\n",
      "2997  0.066978              0.976126   2997\n",
      "2998  0.067328              0.976640   2998\n",
      "2999  0.061419              0.978822   2999\n",
      "true count 2177  false count 421\n",
      "accuracy rate 0.8379522709776751\n",
      "\n",
      "1.4252448917705216\n",
      "............................................................0.09700693529395203\n",
      "............................................................0.08207517782803096\n",
      "............................................................0.07373006235769404\n",
      "............................................................0.0645579108658773\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.061840              0.978052   2995\n",
      "2996  0.061017              0.977795   2996\n",
      "2997  0.062474              0.978437   2997\n",
      "2998  0.064845              0.976126   2998\n",
      "2999  0.057873              0.976255   2999\n",
      "true count 2172  false count 426\n",
      "accuracy rate 0.836027713625866\n",
      "\n",
      "1.3787712741458145\n",
      "............................................................0.1032300778149319\n",
      "............................................................0.07629185223022167\n",
      "............................................................0.06677021611706159\n",
      "............................................................0.0651912127082713\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.058037              0.978565   2995\n",
      "2996  0.059550              0.978052   2996\n",
      "2997  0.064415              0.976768   2997\n",
      "2998  0.064769              0.975741   2998\n",
      "2999  0.056047              0.979335   2999\n",
      "true count 2202  false count 396\n",
      "accuracy rate 0.8475750577367206\n",
      "\n",
      "1.4131409418535483\n",
      "............................................................0.09676600777845437\n",
      "............................................................0.0760317868982842\n",
      "............................................................0.06847241584260838\n",
      "............................................................0.06829722874997868\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.066424              0.978437   2995\n",
      "2996  0.061006              0.976896   2996\n",
      "2997  0.059997              0.977281   2997\n",
      "2998  0.059996              0.978437   2998\n",
      "2999  0.060849              0.978180   2999\n",
      "true count 2182  false count 416\n",
      "accuracy rate 0.8398768283294842\n",
      "\n",
      "1.4069576085478301\n",
      "............................................................0.100180640724405\n",
      "............................................................0.07816298499144207\n",
      "............................................................0.07627960192064712\n",
      "............................................................0.0639836467475468\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.058963              0.978052   2995\n",
      "2996  0.061579              0.978437   2996\n",
      "2997  0.069253              0.974073   2997\n",
      "2998  0.066906              0.975485   2998\n",
      "2999  0.063147              0.977025   2999\n",
      "true count 2191  false count 407\n",
      "accuracy rate 0.8433410315627405\n",
      "\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 26, 1, 32)         1184      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 26, 1, 32)         128       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 26, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 832)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 400)               333200    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 34)                13634     \n",
      "=================================================================\n",
      "Total params: 348,146\n",
      "Trainable params: 348,082\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "1.485433492790886\n",
      "............................................................0.10227694882154312\n",
      "............................................................0.08352197360086236\n",
      "............................................................0.0757903103313708\n",
      "............................................................0.0671784134540803\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.069886              0.974971   2995\n",
      "2996  0.067354              0.975356   2996\n",
      "2997  0.062994              0.974971   2997\n",
      "2998  0.064581              0.975613   2998\n",
      "2999  0.070870              0.974843   2999\n",
      "true count 2199  false count 399\n",
      "accuracy rate 0.8464203233256351\n",
      "\n",
      "1.4461900328980868\n",
      "............................................................0.08981649701650543\n",
      "............................................................0.08128175768007165\n",
      "............................................................0.07319984829598138\n",
      "............................................................0.06082338272596187\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.068903              0.975870   2995\n",
      "2996  0.061950              0.977410   2996\n",
      "2997  0.059670              0.976896   2997\n",
      "2998  0.064647              0.977281   2998\n",
      "2999  0.061278              0.980362   2999\n",
      "true count 2217  false count 381\n",
      "accuracy rate 0.8533487297921478\n",
      "\n",
      "1.441918469212845\n",
      "............................................................0.09674702379902739\n",
      "............................................................0.08108143120556553\n",
      "............................................................0.06780613198333199\n",
      "............................................................0.06485900389822637\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.062921              0.978308   2995\n",
      "2996  0.060903              0.978308   2996\n",
      "2997  0.067258              0.976255   2997\n",
      "2998  0.055978              0.979207   2998\n",
      "2999  0.065304              0.976511   2999\n",
      "true count 2195  false count 403\n",
      "accuracy rate 0.8448806774441878\n",
      "\n",
      "1.4609801638892947\n",
      "............................................................0.0955631764632657\n",
      "............................................................0.07743825894669167\n",
      "............................................................0.07730678950371025\n",
      "............................................................0.06802106698578818\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.058113              0.979207   2995\n",
      "2996  0.063444              0.979207   2996\n",
      "2997  0.065151              0.974971   2997\n",
      "2998  0.060291              0.976768   2998\n",
      "2999  0.063713              0.977025   2999\n",
      "true count 2206  false count 392\n",
      "accuracy rate 0.8491147036181679\n",
      "\n",
      "1.4450082178829478\n",
      "............................................................0.10441661791577352\n",
      "............................................................0.07638657271207917\n",
      "............................................................0.0753759198490721\n",
      "............................................................0.07028047468820703\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.063450              0.977153   2995\n",
      "2996  0.062794              0.978693   2996\n",
      "2997  0.066223              0.976768   2997\n",
      "2998  0.065789              0.977281   2998\n",
      "2999  0.065156              0.975870   2999\n",
      "true count 2212  false count 386\n",
      "accuracy rate 0.8514241724403387\n",
      "\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 1, 1, 32)          4384      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 1, 1, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 400)               13200     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 34)                13634     \n",
      "=================================================================\n",
      "Total params: 31,346\n",
      "Trainable params: 31,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "1.6035126648731401\n",
      "............................................................0.7464375866574877\n",
      "............................................................0.7101952676870384\n",
      "............................................................0.6905015001032597\n",
      "............................................................0.7085070592679868\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.685896              0.752407   2995\n",
      "2996  0.679505              0.749326   2996\n",
      "2997  0.691324              0.747401   2997\n",
      "2998  0.679569              0.745476   2998\n",
      "2999  0.687857              0.739571   2999\n",
      "true count 1953  false count 645\n",
      "accuracy rate 0.7517321016166282\n",
      "\n",
      "1.6185274610408018\n",
      "............................................................0.7414521367723408\n",
      "............................................................0.7060879773558708\n",
      "............................................................0.6930019781825448\n",
      "............................................................0.6777123942973142\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.676642              0.743037   2995\n",
      "2996  0.679558              0.741625   2996\n",
      "2997  0.688774              0.738673   2997\n",
      "2998  0.675955              0.750866   2998\n",
      "2999  0.680310              0.745476   2999\n",
      "true count 1890  false count 708\n",
      "accuracy rate 0.7274826789838337\n",
      "\n",
      "1.5852099053285316\n",
      "............................................................0.7445898528368968\n",
      "............................................................0.7143482609104856\n",
      "............................................................0.6983540117350459\n",
      "............................................................0.6853076847890056\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.699810              0.739315   2995\n",
      "2996  0.688433              0.748428   2996\n",
      "2997  0.692625              0.743935   2997\n",
      "2998  0.677732              0.744449   2998\n",
      "2999  0.686290              0.740726   2999\n",
      "true count 2022  false count 576\n",
      "accuracy rate 0.7782909930715936\n",
      "\n",
      "1.603913869788628\n",
      "............................................................0.7369865024828847\n",
      "............................................................0.7141163010007227\n",
      "............................................................0.6964633039371788\n",
      "............................................................0.692703798904818\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.682217              0.742010   2995\n",
      "2996  0.687550              0.745732   2996\n",
      "2997  0.671314              0.750738   2997\n",
      "2998  0.674274              0.745476   2998\n",
      "2999  0.683432              0.744320   2999\n",
      "true count 1903  false count 695\n",
      "accuracy rate 0.7324865280985373\n",
      "\n",
      "1.610052074184621\n",
      "............................................................0.7437061925185934\n",
      "............................................................0.7056619854001542\n",
      "............................................................0.701893969565083\n",
      "............................................................0.6916205584888142\n",
      "............................................................\n",
      "           loss  categorical_accuracy  epoch\n",
      "2995  0.672942              0.751123   2995\n",
      "2996  0.700785              0.740598   2996\n",
      "2997  0.698941              0.739058   2997\n",
      "2998  0.690664              0.742780   2998\n",
      "2999  0.696286              0.737518   2999\n",
      "true count 1849  false count 749\n",
      "accuracy rate 0.7117013086989993\n",
      "\n",
      "result acc mean\n",
      " {3: 0.97792, 9: 0.97692, 34: 0.74152}\n",
      "result acc std\n",
      " {3: 0.001136, 9: 0.001868, 34: 0.002964}\n",
      "pred accuracy rate(mean)\n",
      " {3: 0.841, 9: 0.849, 34: 0.7403}\n",
      "time (sec)\n",
      " {3: 12697.1, 9: 30391.8, 34: 40974.4}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 3\n",
    "n_trials = 5\n",
    "EPOCHS = 3000\n",
    "kernel_size_list = [3, 9, 34]\n",
    "train_policy_network(num, kernel_size_list, n_trials, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfYvA4pEoORq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mini_mahjong_PNplot_tsukijiCNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
